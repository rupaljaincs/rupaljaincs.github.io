---
layout: post
title: Reinforcement Learning for AI
subtitle: Turning Recursive AI on its head - using Reinforcement Learning as an approach to attain some semblance of ethicality in AI 
bigimg: /img/path.jpg
tags: [open-source, internship]
---

## Can we evaluate and incentivize AI truthfulness?

We have all known the frightening consequences of Artificial General Intelligence that it could learn from humans and imitate us to an extent that it intellectually surpasses any form of viable human intelligence, thus posing a risk to human civilisation. Widely regarded as the “holy grail” of AI research, AGI allows them to tackle challenges that weren’t considered during their design phase.

Recursive AI is an approach to Artificial General Intelligence that learns from its own mistakes and becomes more sensitive and receptive to a wider human spectrum. And that allows a system to make adjustments to its own functionality resulting in improved performance. 

Every time a system fails humanity, it leaves crumbs, like a serial killer, waiting to be caught. We just need to see the crumbs as the clues they are, the hardest part. Sometimes, the most brutal aspect of somethings turns out to be a chink in its armor. Disguising its weaknesses as strengths, the recursive AI. Much like every human at their core.

> “To iterate is human, to recurse, divine”

Here, I see an opportunity for using Reinforcement Learning to teach recursive AI systems to make better, more ethical decisions with each iteration. We can come up with a handbook of what use cases we need the system to make ethical choices upon and train to seek ethical choices for reward maximization.

(Footnote: Now, coming up with an internationally agreed-upon standard of ethics training is a Goliath of a task.)
